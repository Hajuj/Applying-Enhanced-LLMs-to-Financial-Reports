{
  "config": {
    "activation_function": "gelu",
    "bias": true,
    "embedding_size": 768,
    "head_type": "masked_lm",
    "label2id": null,
    "layer_norm": true,
    "layers": 2,
    "shift_labels": false,
    "vocab_size": 30522
  },
  "hidden_size": 768,
  "model_class": "DistilBertAdapterModel",
  "model_name": "distilbert-base-uncased",
  "model_type": "distilbert",
  "name": "default",
  "version": "0.1.2"
}