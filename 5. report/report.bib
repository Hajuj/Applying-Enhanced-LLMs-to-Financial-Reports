%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jonas Gottal at 2024-04-27 20:13:58 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{Panchenko2007,
	author = {Valentyn Panchenko},
	date-added = {2024-04-27 20:13:46 +0200},
	date-modified = {2024-04-27 20:13:58 +0200},
	doi = {10.1080/13518470500459782},
	eprint = {https://doi.org/10.1080/13518470500459782},
	journal = {The European Journal of Finance},
	number = {2},
	pages = {165 -- 179},
	publisher = {Routledge},
	title = {Impact of Analysts' Recommendations on Stock Performance},
	url = {https://doi.org/10.1080/13518470500459782},
	volume = {13},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1080/13518470500459782}}

@article{Su2020,
	abstract = {Abstract This study examines the time-varying performance of investment strategies following analyst recommendation revisions in the UK stock market, with specific emphasis on the impact of changing market conditions. We find a negative relationship between the recommendation performance and market conditions as measured in terms of past market return and market volatility. In particular, the upgrade (downgrade) portfolio generates significantly positive (negative) net abnormal returns in bad market conditions (e.g., the dot-com bubble burst in 2000 and the credit crisis in 2007), but not in other periods of time. Moreover, our non-temporal threshold regression analysis shows that the reported negative relationship disappears when market conditions become better, i.e., when the past market return (market volatility) is higher (lower) than a certain level, indicating the importance of taking non-linearity into account in the long sample period as examined in this study. Our time-series bootstrap simulations further confirm that the superior recommendation performance in bad market conditions is not due to random chance; analysts have certain skills in making valuable up/downward revisions in bad markets.},
	author = {Su, Chen and Zhang, Hanxiong and Hudson, Robert S.},
	date-added = {2024-04-27 20:10:01 +0200},
	date-modified = {2024-04-27 20:10:12 +0200},
	doi = {https://doi.org/10.1111/fmii.12126},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/fmii.12126},
	journal = {Financial Markets, Institutions \& Instruments},
	keywords = {analyst recommendation revisions, bootstrap simulations, market conditions, non-temporal threshold regression model},
	number = {2},
	pages = {65 -- 89},
	title = {The time-varying performance of UK analyst recommendation revisions: Do market conditions matter?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/fmii.12126},
	volume = {29},
	year = {2020},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/fmii.12126},
	bdsk-url-2 = {https://doi.org/10.1111/fmii.12126}}

@article{Brauer2018,
	abstract = { As visible and knowledgeable experts who constantly collect, analyze, and disseminate information about the future prospects of publicly listed firms, financial analysts fulfill an important information brokerage and monitoring function for investors. By providing investment advice, financial analysts also influence the demand for a firm's stock and thus its price. Executives pay close attention to financial analysts' earnings forecasts and recommendations, so much so that they are frequently criticized for excessive focus on their forecasts at the expense of the long-term interests of the firm. But while research on analysts in strategic management is steadily growing, we lack a coherent understanding of the extent and nature of analysts' diverse influences on executives' and investors' decision making and the context in which analysts operate. This is largely due to the fragmentation of the literature and the absence of prior reviews or meta-analyses of the topic. By organizing, synthesizing, and analyzing extant research efforts on analysts in the various domains of strategic management research, we aim to advance our knowledge on the influence of analysts on firms and investors. Further, we hope that our analyses and recommendations help further increase research coverage on this important organizational stakeholder. },
	author = {Matthias Brauer and Margarethe Wiersema},
	date-added = {2024-04-27 20:01:19 +0200},
	date-modified = {2024-04-27 20:01:30 +0200},
	doi = {10.1177/0149206317734900},
	eprint = {https://doi.org/10.1177/0149206317734900},
	journal = {Journal of Management},
	number = {1},
	pages = {218 -- 248},
	title = {Analyzing Analyst Research: A Review of Past Coverage and Recommendations for Future Research},
	url = {https://doi.org/10.1177/0149206317734900},
	volume = {44},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1177/0149206317734900}}

@inproceedings{Kim2023,
	abstract = {This paper examines the use of Large Language Models (LLMs), specifically BERT-based models and GPT-3.5, in the sentiment analysis of Korean financial analyst reports. Due to the specialized language in these reports, traditional natural language processing techniques often prove insufficient, making LLMs a better alternative. These models are capable of understanding the complexity and subtlety of the language, allowing for a more nuanced interpretation of the data. We focus our study on the extraction of sentiment scores from these reports, using them to construct and test investment strategies. Given that Korean analyst reports present unique linguistic challenges and a significant `buy' recommendation bias, we employ LLMs fine-tuned for the Korean language and Korean financial texts. The aim of this study is to investigate and compare the effectiveness of LLMs in enhancing the sentiment analysis of financial reports, and subsequently utilize the sentiment scores to construct and test investment strategies, thereby evaluating these models' potential in extracting valuable insights from the reports. The code is available at https://github.com/msraask3.},
	address = {New York, NY, USA},
	author = {Kim, Seonmi and Kim, Seyoung and Kim, Yejin and Park, Junpyo and Kim, Seongjin and Kim, Moolkyeol and Sung, Chang Hwan and Hong, Joohwan and Lee, Yongjae},
	booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
	date-added = {2024-04-27 19:45:46 +0200},
	date-modified = {2024-04-27 19:46:00 +0200},
	doi = {10.1145/3604237.3627721},
	isbn = {9798400702402},
	location = {<conf-loc>, <city>Brooklyn</city>, <state>NY</state>, <country>USA</country>, </conf-loc>},
	numpages = {9},
	pages = {383 -- 391},
	publisher = {Association for Computing Machinery},
	series = {ICAIF '23},
	title = {LLMs Analyzing the Analysts: Do BERT and GPT Extract More Value from Financial Analyst Reports?},
	url = {https://doi.org/10.1145/3604237.3627721},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1145/3604237.3627721}}

@inproceedings{Palmer2018,
	author = {Palmer, Matthias and Eickhoff, Matthias and Muntermann, Jan},
	booktitle = {Research Papers},
	date-added = {2024-04-27 19:36:03 +0200},
	date-modified = {2024-04-27 19:38:42 +0200},
	month = {06},
	title = {Detecting Herding Behavior Using Topic Mining: The Case of Financial Analysts},
	volume = {97},
	year = {2018}}

@article{Anderson2020,
	author = {Anderson, Anders and Jones, Howard and Martinez, Jos{\'e} Vicente},
	date-added = {2024-04-27 19:27:44 +0200},
	date-modified = {2024-04-27 19:27:53 +0200},
	doi = {10.1017/S0022109019000413},
	journal = {Journal of Financial and Quantitative Analysis},
	number = {6},
	pages = {1915 -- 1945},
	title = {Measuring the Added Value of Stock Recommendations},
	volume = {55},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1017/S0022109019000413}}

@inproceedings{Deng2023,
	abstract = {Market sentiment analysis on social media content requires knowledge of both financial markets and social media jargon, which makes it a challenging task for human raters. The resulting lack of high-quality labeled data stands in the way of conventional supervised learning methods. Instead, we approach this problem using semi-supervised learning with a large language model (LLM). Our pipeline generates weak financial sentiment labels for Reddit posts with an LLM and then uses that data to train a small model that can be served in production. We find that prompting the LLM to produce Chain-of-Thought summaries and forcing it through several reasoning paths helps generate more stable and accurate labels, while using a regression loss further improves distillation quality. With only a handful of prompts, the final model performs on par with existing supervised models. Though production applications of our model are limited by ethical considerations, the model's competitive performance points to the great potential of using LLMs for tasks that otherwise require skill-intensive annotation.},
	address = {New York, NY, USA},
	author = {Deng, Xiang and Bashlovkina, Vasilisa and Han, Feng and Baumgartner, Simon and Bendersky, Michael},
	booktitle = {Companion Proceedings of the ACM Web Conference 2023},
	date-added = {2024-04-27 19:26:23 +0200},
	date-modified = {2024-04-27 19:26:35 +0200},
	doi = {10.1145/3543873.3587324},
	isbn = {9781450394192},
	keywords = {Finance, Large Language Model, Sentiment Analysis, Social Media},
	location = {<conf-loc>, <city>Austin</city>, <state>TX</state>, <country>USA</country>, </conf-loc>},
	numpages = {4},
	pages = {107 -- 110},
	publisher = {Association for Computing Machinery},
	series = {WWW '23 Companion},
	title = {What do LLMs Know about Financial Markets? A Case Study on Reddit Market Sentiment Analysis},
	url = {https://doi.org/10.1145/3543873.3587324},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1145/3543873.3587324}}

@misc{Zhao2024,
	archiveprefix = {arXiv},
	author = {Huaqin Zhao and Zhengliang Liu and Zihao Wu and Yiwei Li and Tianze Yang and Peng Shu and Shaochen Xu and Haixing Dai and Lin Zhao and Gengchen Mai and Ninghao Liu and Tianming Liu},
	date-added = {2024-04-27 19:24:05 +0200},
	date-modified = {2024-04-27 19:24:14 +0200},
	eprint = {2401.11641},
	primaryclass = {cs.CL},
	title = {Revolutionizing Finance with LLMs: An Overview of Applications and Insights},
	year = {2024}}

@misc{Raschka2023,
	author = {Raschka, Sebastian},
	date-added = {2024-04-27 19:08:28 +0200},
	date-modified = {2024-04-27 19:08:36 +0200},
	journal = {Ahead of AI},
	month = {May},
	title = {Finetuning LLMs Efficiently with Adapters},
	url = {https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters},
	year = {2023},
	bdsk-url-1 = {https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters}}

@book{Hastie2009,
	address = {New York, US},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	date-added = {2024-04-27 13:22:18 +0200},
	date-modified = {2024-04-27 13:22:18 +0200},
	doi = {10.1007/978-0-387-84858-7},
	edition = {2nd},
	publisher = {Springer New York},
	title = {The Elements of Statistical Learning},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1007/978-0-387-84858-7}}


@book{Hull2021,
	address = {Boston},
	author = {Hull, John C.},
	date-added = {2022-05-19 15:58:51 +0200},
	date-modified = {2022-05-19 16:00:32 +0200},
	edition = {11th},
	publisher = {Pearson},
	title = {Options, Futures, and other Derivatives},
	year = {2021}}


@misc{Kokhlikyan2020,
	archiveprefix = {arXiv},
	author = {Narine Kokhlikyan and Vivek Miglani and Miguel Martin and Edward Wang and Bilal Alsallakh and Jonathan Reynolds and Alexander Melnikov and Natalia Kliushkina and Carlos Araya and Siqi Yan and Orion Reblitz-Richardson},
	eprint = {2009.07896},
	primaryclass = {cs.LG},
	title = {Captum: A unified and generic model interpretability library for PyTorch},
	year = {2020}}

@book{Kauermann2021,
	address = {Cham, Switzerland},
	author = {Kauermann, G\"{o}ran and K\"{u}chenhoff, Helmut and Heumann, Christian},
	date-added = {2022-01-17 18:47:05 +0100},
	date-modified = {2023-05-04 08:14:59 +0200},
	doi = {10.1007/978-3-030-69827-0},
	publisher = {Springer Nature Switzerland},
	title = {Statistical Foundations, Reasoning and Inference},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-030-69827-0}}

@misc{Poth2023,
	archiveprefix = {arXiv},
	author = {Clifton Poth and Hannah Sterz and Indraneil Paul and Sukannya Purkayastha and Leon Engl{\"a}nder and Timo Imhof and Ivan Vuli{\'c} and Sebastian Ruder and Iryna Gurevych and Jonas Pfeiffer},
	eprint = {2311.11077},
	primaryclass = {cs.CL},
	title = {Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning},
	year = {2023}}

@book{Russell2021,
	address = {Harlow, United Kingdom},
	author = {Russell, Stuart Jonathan AND Norvig, Peter},
	date-added = {2021-12-03 17:39:55 +0100},
	date-modified = {2023-05-04 07:20:09 +0200},
	edition = {4th},
	publisher = {Prentice Hall},
	series = {Pearson Education},
	title = {Artificial Intelligence -- A Modern Approach, Global Edition},
	year = {2021}}



@book{Hosmer2013,
	author = {Hosmer Jr., David W. and Lemeshow, Stanley and Sturdivant, Rodney X.},
	date-added = {2022-06-27 16:46:25 +0200},
	date-modified = {2022-06-27 16:50:00 +0200},
	edition = {3rd},
	publisher = {John Wiley \& Sons},
	title = {Applied Logistic Regression},
	year = {2013}}
